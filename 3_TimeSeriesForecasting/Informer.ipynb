{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IM6CZzW_CH0"
   },
   "source": [
    "# Informer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdaIHYx4_ECL"
   },
   "source": [
    "## Download code and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2547,
     "status": "ok",
     "timestamp": 1650152273086,
     "user": {
      "displayName": "Lam Ngo",
      "userId": "10830440175711572344"
     },
     "user_tz": -480
    },
    "id": "SA_i2gbl-rn-",
    "outputId": "10c2ef62-8559-4add-b380-3350b0bfd494"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Informer2020'...\n",
      "remote: Enumerating objects: 573, done.\u001b[K\n",
      "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
      "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
      "remote: Total 573 (delta 15), reused 19 (delta 7), pack-reused 535\u001b[K\n",
      "Receiving objects: 100% (573/573), 6.49 MiB | 18.56 MiB/s, done.\n",
      "Resolving deltas: 100% (321/321), done.\n",
      "Cloning into 'ETDataset'...\n",
      "remote: Enumerating objects: 187, done.\u001b[K\n",
      "remote: Counting objects: 100% (187/187), done.\u001b[K\n",
      "remote: Compressing objects: 100% (184/184), done.\u001b[K\n",
      "remote: Total 187 (delta 66), reused 13 (delta 2), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (187/187), 3.85 MiB | 12.29 MiB/s, done.\n",
      "Resolving deltas: 100% (66/66), done.\n",
      "ETDataset  Informer2020  sample_data\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/zhouhaoyi/Informer2020.git\n",
    "!git clone https://github.com/zhouhaoyi/ETDataset.git\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1650152273088,
     "user": {
      "displayName": "Lam Ngo",
      "userId": "10830440175711572344"
     },
     "user_tz": -480
    },
    "id": "b5GFng7v7Eq0"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if not 'Informer2020' in sys.path:\n",
    "    sys.path += ['Informer2020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18356,
     "status": "ok",
     "timestamp": 1650152291434,
     "user": {
      "displayName": "Lam Ngo",
      "userId": "10830440175711572344"
     },
     "user_tz": -480
    },
    "id": "VdB-FhUHRYKh",
    "outputId": "47451f05-e4e4-4616-9f17-7a982a8d5e59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1650152291436,
     "user": {
      "displayName": "Lam Ngo",
      "userId": "10830440175711572344"
     },
     "user_tz": -480
    },
    "id": "YW9TS6jp_YXc"
   },
   "outputs": [],
   "source": [
    "# !pip install -r ./Informer2020/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIjZdN5e_SWe"
   },
   "source": [
    "## Experiments: Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5137,
     "status": "ok",
     "timestamp": 1650152296563,
     "user": {
      "displayName": "Lam Ngo",
      "userId": "10830440175711572344"
     },
     "user_tz": -480
    },
    "id": "RPdt-Kwc_RRZ"
   },
   "outputs": [],
   "source": [
    "from utils.tools import dotdict\n",
    "from exp.exp_informer import Exp_Informer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1650152297187,
     "user": {
      "displayName": "Lam Ngo",
      "userId": "10830440175711572344"
     },
     "user_tz": -480
    },
    "id": "6mx2dnwY9dWi"
   },
   "outputs": [],
   "source": [
    "args = dotdict()\n",
    "\n",
    "args.model = 'informer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n",
    "args.data = 'custom' # data\n",
    "args.root_path = './drive/MyDrive/AIST_Project/traffic/' # root path of data file\n",
    "args.data_path = 'data.csv' # data file\n",
    "args.features = 'MS' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n",
    "args.target = 'traffic_volume' # target feature in S or MS task\n",
    "args.freq = 'h' # freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h\n",
    "args.checkpoints = './informer_checkpoints' # location of model checkpoints\n",
    "\n",
    "args.seq_len = 48 # input sequence length of Informer encoder\n",
    "args.label_len = 48 # start token length of Informer decoder\n",
    "args.pred_len = 1 # prediction sequence length\n",
    "# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n",
    "\n",
    "args.enc_in = 7 # encoder input size\n",
    "args.dec_in = 7 # decoder input size\n",
    "args.c_out = 7 # output size\n",
    "args.factor = 5 # probsparse attn factor\n",
    "args.d_model = 512 # dimension of model\n",
    "args.n_heads = 8 # num of heads\n",
    "args.e_layers = 2 # num of encoder layers\n",
    "args.d_layers = 1 # num of decoder layers\n",
    "args.d_ff = 2048 # dimension of fcn in model\n",
    "args.dropout = 0.05 # dropout\n",
    "args.attn = 'prob' # attention used in encoder, options:[prob, full]\n",
    "args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n",
    "args.activation = 'gelu' # activation\n",
    "args.distil = True # whether to use distilling in encoder\n",
    "args.output_attention = False # whether to output attention in ecoder\n",
    "args.mix = True\n",
    "args.padding = 0\n",
    "args.freq = 'h'\n",
    "\n",
    "args.batch_size = 32 \n",
    "args.learning_rate = 0.0001\n",
    "args.loss = 'mse'\n",
    "args.lradj = 'type1'\n",
    "args.use_amp = False # whether to use automatic mixed precision training\n",
    "\n",
    "args.num_workers = 0\n",
    "args.itr = 1\n",
    "args.train_epochs = 100\n",
    "args.patience = 5\n",
    "args.des = 'exp'\n",
    "\n",
    "args.use_gpu = True if torch.cuda.is_available() else False\n",
    "args.gpu = 0\n",
    "\n",
    "args.use_multi_gpu = False\n",
    "args.devices = '0,1,2,3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1650152297188,
     "user": {
      "displayName": "Lam Ngo",
      "userId": "10830440175711572344"
     },
     "user_tz": -480
    },
    "id": "k_BCYODAwKl9"
   },
   "outputs": [],
   "source": [
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    args.devices = args.devices.replace(' ','')\n",
    "    device_ids = args.devices.split(',')\n",
    "    args.device_ids = [int(id_) for id_ in device_ids]\n",
    "    args.gpu = args.device_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1650152297188,
     "user": {
      "displayName": "Lam Ngo",
      "userId": "10830440175711572344"
     },
     "user_tz": -480
    },
    "id": "53o3pZ809p-a"
   },
   "outputs": [],
   "source": [
    "# Set augments by using data name\n",
    "data_parser = {\n",
    "    'custom':{'data':'traffic_data2.csv','T':'traffic_volume','M':[7,7,7],'S':[1,1,1],'MS':[47,47,1]},\n",
    "}\n",
    "if args.data in data_parser.keys():\n",
    "    data_info = data_parser[args.data]\n",
    "    args.data_path = data_info['data']\n",
    "    args.target = data_info['T']\n",
    "    args.enc_in, args.dec_in, args.c_out = data_info[args.features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1650152297189,
     "user": {
      "displayName": "Lam Ngo",
      "userId": "10830440175711572344"
     },
     "user_tz": -480
    },
    "id": "yZ5Q2vyKwSfk"
   },
   "outputs": [],
   "source": [
    "args.detail_freq = args.freq\n",
    "args.freq = args.freq[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1650152297189,
     "user": {
      "displayName": "Lam Ngo",
      "userId": "10830440175711572344"
     },
     "user_tz": -480
    },
    "id": "ywY-umrw-mHO",
    "outputId": "b3471110-d20c-4da5-babc-6478923e10cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "{'model': 'informer', 'data': 'custom', 'root_path': './drive/MyDrive/AIST_Project/traffic/', 'data_path': 'traffic_data2.csv', 'features': 'MS', 'target': 'traffic_volume', 'freq': 'h', 'checkpoints': './informer_checkpoints', 'seq_len': 48, 'label_len': 48, 'pred_len': 1, 'enc_in': 47, 'dec_in': 47, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'batch_size': 32, 'learning_rate': 0.0001, 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 100, 'patience': 5, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'detail_freq': 'h'}\n"
     ]
    }
   ],
   "source": [
    "print('Args in experiment:')\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1650152297190,
     "user": {
      "displayName": "Lam Ngo",
      "userId": "10830440175711572344"
     },
     "user_tz": -480
    },
    "id": "KVHZhRB4-on9"
   },
   "outputs": [],
   "source": [
    "Exp = Exp_Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1693035,
     "status": "ok",
     "timestamp": 1650153990216,
     "user": {
      "displayName": "Lam Ngo",
      "userId": "10830440175711572344"
     },
     "user_tz": -480
    },
    "id": "928tzaA2AA2g",
    "outputId": "b44cc8e7-a012-48ac-84d5-3217396edf1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_custom_ftMS_sl48_ll48_pl1_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 33687\n",
      "val 4821\n",
      "test 9638\n",
      "\titers: 100, epoch: 1 | loss: 0.3227528\n",
      "\tspeed: 0.0563s/iter; left time: 5917.5437s\n",
      "\titers: 200, epoch: 1 | loss: 0.3393736\n",
      "\tspeed: 0.0520s/iter; left time: 5458.9728s\n",
      "\titers: 300, epoch: 1 | loss: 0.2240662\n",
      "\tspeed: 0.0523s/iter; left time: 5482.7411s\n",
      "\titers: 400, epoch: 1 | loss: 0.1340524\n",
      "\tspeed: 0.0525s/iter; left time: 5500.2220s\n",
      "\titers: 500, epoch: 1 | loss: 0.1533166\n",
      "\tspeed: 0.0525s/iter; left time: 5492.6574s\n",
      "\titers: 600, epoch: 1 | loss: 0.1277189\n",
      "\tspeed: 0.0526s/iter; left time: 5501.7899s\n",
      "\titers: 700, epoch: 1 | loss: 0.0499923\n",
      "\tspeed: 0.0528s/iter; left time: 5520.6854s\n",
      "\titers: 800, epoch: 1 | loss: 0.0753669\n",
      "\tspeed: 0.0528s/iter; left time: 5514.8059s\n",
      "\titers: 900, epoch: 1 | loss: 0.1578721\n",
      "\tspeed: 0.0531s/iter; left time: 5543.4212s\n",
      "\titers: 1000, epoch: 1 | loss: 0.0923963\n",
      "\tspeed: 0.0530s/iter; left time: 5525.4439s\n",
      "Epoch: 1 cost time: 55.800984621047974\n",
      "Epoch: 1, Steps: 1052 | Train Loss: 0.2165749 Vali Loss: 0.0683657 Test Loss: 0.0679053\n",
      "Validation loss decreased (inf --> 0.068366).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0761359\n",
      "\tspeed: 0.1818s/iter; left time: 18913.0902s\n",
      "\titers: 200, epoch: 2 | loss: 0.1324430\n",
      "\tspeed: 0.0578s/iter; left time: 6005.4477s\n",
      "\titers: 300, epoch: 2 | loss: 0.2296895\n",
      "\tspeed: 0.0610s/iter; left time: 6330.6122s\n",
      "\titers: 400, epoch: 2 | loss: 0.1071972\n",
      "\tspeed: 0.0544s/iter; left time: 5639.6849s\n",
      "\titers: 500, epoch: 2 | loss: 0.0643275\n",
      "\tspeed: 0.0545s/iter; left time: 5644.5252s\n",
      "\titers: 600, epoch: 2 | loss: 0.1046136\n",
      "\tspeed: 0.0545s/iter; left time: 5645.3544s\n",
      "\titers: 700, epoch: 2 | loss: 0.0940862\n",
      "\tspeed: 0.0545s/iter; left time: 5637.8445s\n",
      "\titers: 800, epoch: 2 | loss: 0.2032837\n",
      "\tspeed: 0.0545s/iter; left time: 5636.4655s\n",
      "\titers: 900, epoch: 2 | loss: 0.0426452\n",
      "\tspeed: 0.0546s/iter; left time: 5635.8660s\n",
      "\titers: 1000, epoch: 2 | loss: 0.0301825\n",
      "\tspeed: 0.0549s/iter; left time: 5661.0657s\n",
      "Epoch: 2 cost time: 58.3166184425354\n",
      "Epoch: 2, Steps: 1052 | Train Loss: 0.1028958 Vali Loss: 0.0578811 Test Loss: 0.0532916\n",
      "Validation loss decreased (0.068366 --> 0.057881).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0530591\n",
      "\tspeed: 0.1886s/iter; left time: 19422.2380s\n",
      "\titers: 200, epoch: 3 | loss: 0.0761092\n",
      "\tspeed: 0.0554s/iter; left time: 5703.0312s\n",
      "\titers: 300, epoch: 3 | loss: 0.1319424\n",
      "\tspeed: 0.0554s/iter; left time: 5697.8225s\n",
      "\titers: 400, epoch: 3 | loss: 0.0726701\n",
      "\tspeed: 0.0557s/iter; left time: 5715.4187s\n",
      "\titers: 500, epoch: 3 | loss: 0.0380467\n",
      "\tspeed: 0.0557s/iter; left time: 5715.0095s\n",
      "\titers: 600, epoch: 3 | loss: 0.0449604\n",
      "\tspeed: 0.0556s/iter; left time: 5703.4845s\n",
      "\titers: 700, epoch: 3 | loss: 0.1538233\n",
      "\tspeed: 0.0558s/iter; left time: 5711.1899s\n",
      "\titers: 800, epoch: 3 | loss: 0.0594020\n",
      "\tspeed: 0.0559s/iter; left time: 5721.7836s\n",
      "\titers: 900, epoch: 3 | loss: 0.0819015\n",
      "\tspeed: 0.0563s/iter; left time: 5751.8248s\n",
      "\titers: 1000, epoch: 3 | loss: 0.1642964\n",
      "\tspeed: 0.0561s/iter; left time: 5724.4414s\n",
      "Epoch: 3 cost time: 58.64927840232849\n",
      "Epoch: 3, Steps: 1052 | Train Loss: 0.0783283 Vali Loss: 0.0438727 Test Loss: 0.0456783\n",
      "Validation loss decreased (0.057881 --> 0.043873).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0577744\n",
      "\tspeed: 0.1920s/iter; left time: 19568.7867s\n",
      "\titers: 200, epoch: 4 | loss: 0.1162995\n",
      "\tspeed: 0.0564s/iter; left time: 5743.6439s\n",
      "\titers: 300, epoch: 4 | loss: 0.0732225\n",
      "\tspeed: 0.0565s/iter; left time: 5753.4527s\n",
      "\titers: 400, epoch: 4 | loss: 0.2172672\n",
      "\tspeed: 0.0565s/iter; left time: 5739.5113s\n",
      "\titers: 500, epoch: 4 | loss: 0.0667252\n",
      "\tspeed: 0.0564s/iter; left time: 5730.3309s\n",
      "\titers: 600, epoch: 4 | loss: 0.0520915\n",
      "\tspeed: 0.0564s/iter; left time: 5721.1597s\n",
      "\titers: 700, epoch: 4 | loss: 0.0635985\n",
      "\tspeed: 0.0565s/iter; left time: 5721.0521s\n",
      "\titers: 800, epoch: 4 | loss: 0.0860289\n",
      "\tspeed: 0.0570s/iter; left time: 5773.4144s\n",
      "\titers: 900, epoch: 4 | loss: 0.0462222\n",
      "\tspeed: 0.0566s/iter; left time: 5725.7278s\n",
      "\titers: 1000, epoch: 4 | loss: 0.1958872\n",
      "\tspeed: 0.0567s/iter; left time: 5725.1221s\n",
      "Epoch: 4 cost time: 59.50338315963745\n",
      "Epoch: 4, Steps: 1052 | Train Loss: 0.0667165 Vali Loss: 0.0395836 Test Loss: 0.0407399\n",
      "Validation loss decreased (0.043873 --> 0.039584).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0830527\n",
      "\tspeed: 0.1936s/iter; left time: 19529.2325s\n",
      "\titers: 200, epoch: 5 | loss: 0.0362559\n",
      "\tspeed: 0.0565s/iter; left time: 5692.5515s\n",
      "\titers: 300, epoch: 5 | loss: 0.0534702\n",
      "\tspeed: 0.0564s/iter; left time: 5681.9834s\n",
      "\titers: 400, epoch: 5 | loss: 0.0310034\n",
      "\tspeed: 0.0566s/iter; left time: 5691.5726s\n",
      "\titers: 500, epoch: 5 | loss: 0.0333303\n",
      "\tspeed: 0.0564s/iter; left time: 5670.3589s\n",
      "\titers: 600, epoch: 5 | loss: 0.0392919\n",
      "\tspeed: 0.0566s/iter; left time: 5681.2501s\n",
      "\titers: 700, epoch: 5 | loss: 0.0410134\n",
      "\tspeed: 0.0565s/iter; left time: 5667.8042s\n",
      "\titers: 800, epoch: 5 | loss: 0.0927498\n",
      "\tspeed: 0.0565s/iter; left time: 5656.6289s\n",
      "\titers: 900, epoch: 5 | loss: 0.0458555\n",
      "\tspeed: 0.0565s/iter; left time: 5656.2948s\n",
      "\titers: 1000, epoch: 5 | loss: 0.0643799\n",
      "\tspeed: 0.0564s/iter; left time: 5643.8086s\n",
      "Epoch: 5 cost time: 59.44129467010498\n",
      "Epoch: 5, Steps: 1052 | Train Loss: 0.0600006 Vali Loss: 0.0383249 Test Loss: 0.0390481\n",
      "Validation loss decreased (0.039584 --> 0.038325).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0582205\n",
      "\tspeed: 0.1927s/iter; left time: 19239.0310s\n",
      "\titers: 200, epoch: 6 | loss: 0.0627161\n",
      "\tspeed: 0.0564s/iter; left time: 5624.9314s\n",
      "\titers: 300, epoch: 6 | loss: 0.0282170\n",
      "\tspeed: 0.0564s/iter; left time: 5622.3626s\n",
      "\titers: 400, epoch: 6 | loss: 0.0365029\n",
      "\tspeed: 0.0565s/iter; left time: 5619.1742s\n",
      "\titers: 500, epoch: 6 | loss: 0.0366773\n",
      "\tspeed: 0.0565s/iter; left time: 5618.1826s\n",
      "\titers: 600, epoch: 6 | loss: 0.0593551\n",
      "\tspeed: 0.0565s/iter; left time: 5615.9259s\n",
      "\titers: 700, epoch: 6 | loss: 0.0184814\n",
      "\tspeed: 0.0564s/iter; left time: 5599.7318s\n",
      "\titers: 800, epoch: 6 | loss: 0.0771810\n",
      "\tspeed: 0.0566s/iter; left time: 5614.1793s\n",
      "\titers: 900, epoch: 6 | loss: 0.1028930\n",
      "\tspeed: 0.0564s/iter; left time: 5588.0684s\n",
      "\titers: 1000, epoch: 6 | loss: 0.0185105\n",
      "\tspeed: 0.0564s/iter; left time: 5583.0351s\n",
      "Epoch: 6 cost time: 59.41093111038208\n",
      "Epoch: 6, Steps: 1052 | Train Loss: 0.0560155 Vali Loss: 0.0387041 Test Loss: 0.0391455\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0343525\n",
      "\tspeed: 0.1916s/iter; left time: 18929.1329s\n",
      "\titers: 200, epoch: 7 | loss: 0.0944816\n",
      "\tspeed: 0.0566s/iter; left time: 5585.1707s\n",
      "\titers: 300, epoch: 7 | loss: 0.0328641\n",
      "\tspeed: 0.0566s/iter; left time: 5576.4434s\n",
      "\titers: 400, epoch: 7 | loss: 0.0270344\n",
      "\tspeed: 0.0566s/iter; left time: 5571.5221s\n",
      "\titers: 500, epoch: 7 | loss: 0.0360574\n",
      "\tspeed: 0.0566s/iter; left time: 5565.3371s\n",
      "\titers: 600, epoch: 7 | loss: 0.0629825\n",
      "\tspeed: 0.0566s/iter; left time: 5562.0448s\n",
      "\titers: 700, epoch: 7 | loss: 0.0239863\n",
      "\tspeed: 0.0568s/iter; left time: 5577.3733s\n",
      "\titers: 800, epoch: 7 | loss: 0.0461294\n",
      "\tspeed: 0.0566s/iter; left time: 5546.9657s\n",
      "\titers: 900, epoch: 7 | loss: 0.0410042\n",
      "\tspeed: 0.0564s/iter; left time: 5531.0534s\n",
      "\titers: 1000, epoch: 7 | loss: 0.0522835\n",
      "\tspeed: 0.0565s/iter; left time: 5530.5153s\n",
      "Epoch: 7 cost time: 59.522151947021484\n",
      "Epoch: 7, Steps: 1052 | Train Loss: 0.0536360 Vali Loss: 0.0362575 Test Loss: 0.0374160\n",
      "Validation loss decreased (0.038325 --> 0.036258).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1163709\n",
      "\tspeed: 0.1933s/iter; left time: 18895.2835s\n",
      "\titers: 200, epoch: 8 | loss: 0.0456752\n",
      "\tspeed: 0.0566s/iter; left time: 5525.6428s\n",
      "\titers: 300, epoch: 8 | loss: 0.0391036\n",
      "\tspeed: 0.0566s/iter; left time: 5521.5956s\n",
      "\titers: 400, epoch: 8 | loss: 0.0363780\n",
      "\tspeed: 0.0567s/iter; left time: 5523.2063s\n",
      "\titers: 500, epoch: 8 | loss: 0.0604685\n",
      "\tspeed: 0.0567s/iter; left time: 5518.5608s\n",
      "\titers: 600, epoch: 8 | loss: 0.0589131\n",
      "\tspeed: 0.0566s/iter; left time: 5499.5252s\n",
      "\titers: 700, epoch: 8 | loss: 0.0684995\n",
      "\tspeed: 0.0566s/iter; left time: 5493.9019s\n",
      "\titers: 800, epoch: 8 | loss: 0.0541648\n",
      "\tspeed: 0.0569s/iter; left time: 5517.6796s\n",
      "\titers: 900, epoch: 8 | loss: 0.0171470\n",
      "\tspeed: 0.0565s/iter; left time: 5481.4945s\n",
      "\titers: 1000, epoch: 8 | loss: 0.0860618\n",
      "\tspeed: 0.0565s/iter; left time: 5471.8380s\n",
      "Epoch: 8 cost time: 59.57541036605835\n",
      "Epoch: 8, Steps: 1052 | Train Loss: 0.0521092 Vali Loss: 0.0371513 Test Loss: 0.0374144\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0153801\n",
      "\tspeed: 0.1917s/iter; left time: 18531.6785s\n",
      "\titers: 200, epoch: 9 | loss: 0.0315163\n",
      "\tspeed: 0.0566s/iter; left time: 5470.1461s\n",
      "\titers: 300, epoch: 9 | loss: 0.0542426\n",
      "\tspeed: 0.0567s/iter; left time: 5469.6642s\n",
      "\titers: 400, epoch: 9 | loss: 0.0446495\n",
      "\tspeed: 0.0568s/iter; left time: 5475.1467s\n",
      "\titers: 500, epoch: 9 | loss: 0.0196030\n",
      "\tspeed: 0.0567s/iter; left time: 5462.1508s\n",
      "\titers: 600, epoch: 9 | loss: 0.0468115\n",
      "\tspeed: 0.0566s/iter; left time: 5443.5517s\n",
      "\titers: 700, epoch: 9 | loss: 0.0730531\n",
      "\tspeed: 0.0566s/iter; left time: 5435.9679s\n",
      "\titers: 800, epoch: 9 | loss: 0.0335041\n",
      "\tspeed: 0.0565s/iter; left time: 5424.3609s\n",
      "\titers: 900, epoch: 9 | loss: 0.0352927\n",
      "\tspeed: 0.0568s/iter; left time: 5443.2301s\n",
      "\titers: 1000, epoch: 9 | loss: 0.0160039\n",
      "\tspeed: 0.0567s/iter; left time: 5427.2369s\n",
      "Epoch: 9 cost time: 59.59578800201416\n",
      "Epoch: 9, Steps: 1052 | Train Loss: 0.0519303 Vali Loss: 0.0368681 Test Loss: 0.0370764\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0195099\n",
      "\tspeed: 0.1915s/iter; left time: 18314.4132s\n",
      "\titers: 200, epoch: 10 | loss: 0.0270466\n",
      "\tspeed: 0.0567s/iter; left time: 5413.6490s\n",
      "\titers: 300, epoch: 10 | loss: 0.0241778\n",
      "\tspeed: 0.0566s/iter; left time: 5401.6665s\n",
      "\titers: 400, epoch: 10 | loss: 0.0505975\n",
      "\tspeed: 0.0566s/iter; left time: 5397.5426s\n",
      "\titers: 500, epoch: 10 | loss: 0.0614123\n",
      "\tspeed: 0.0565s/iter; left time: 5384.9756s\n",
      "\titers: 600, epoch: 10 | loss: 0.0561018\n",
      "\tspeed: 0.0568s/iter; left time: 5402.0895s\n",
      "\titers: 700, epoch: 10 | loss: 0.0406997\n",
      "\tspeed: 0.0568s/iter; left time: 5399.2047s\n",
      "\titers: 800, epoch: 10 | loss: 0.0234096\n",
      "\tspeed: 0.0565s/iter; left time: 5367.8708s\n",
      "\titers: 900, epoch: 10 | loss: 0.0499315\n",
      "\tspeed: 0.0567s/iter; left time: 5378.1366s\n",
      "\titers: 1000, epoch: 10 | loss: 0.0623560\n",
      "\tspeed: 0.0566s/iter; left time: 5359.6760s\n",
      "Epoch: 10 cost time: 59.57645511627197\n",
      "Epoch: 10, Steps: 1052 | Train Loss: 0.0513964 Vali Loss: 0.0361437 Test Loss: 0.0369231\n",
      "Validation loss decreased (0.036258 --> 0.036144).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0730149\n",
      "\tspeed: 0.1934s/iter; left time: 18288.5889s\n",
      "\titers: 200, epoch: 11 | loss: 0.1237544\n",
      "\tspeed: 0.0565s/iter; left time: 5334.5150s\n",
      "\titers: 300, epoch: 11 | loss: 0.0344378\n",
      "\tspeed: 0.0566s/iter; left time: 5340.8522s\n",
      "\titers: 400, epoch: 11 | loss: 0.0367274\n",
      "\tspeed: 0.0566s/iter; left time: 5335.5550s\n",
      "\titers: 500, epoch: 11 | loss: 0.2230649\n",
      "\tspeed: 0.0566s/iter; left time: 5329.8592s\n",
      "\titers: 600, epoch: 11 | loss: 0.0806230\n",
      "\tspeed: 0.0567s/iter; left time: 5332.5979s\n",
      "\titers: 700, epoch: 11 | loss: 0.0352731\n",
      "\tspeed: 0.0565s/iter; left time: 5314.2085s\n",
      "\titers: 800, epoch: 11 | loss: 0.0529688\n",
      "\tspeed: 0.0566s/iter; left time: 5310.4091s\n",
      "\titers: 900, epoch: 11 | loss: 0.0470844\n",
      "\tspeed: 0.0566s/iter; left time: 5312.6697s\n",
      "\titers: 1000, epoch: 11 | loss: 0.0209785\n",
      "\tspeed: 0.0566s/iter; left time: 5304.5268s\n",
      "Epoch: 11 cost time: 59.560344219207764\n",
      "Epoch: 11, Steps: 1052 | Train Loss: 0.0508474 Vali Loss: 0.0362925 Test Loss: 0.0373361\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.0431268\n",
      "\tspeed: 0.1917s/iter; left time: 17932.6486s\n",
      "\titers: 200, epoch: 12 | loss: 0.0316865\n",
      "\tspeed: 0.0564s/iter; left time: 5271.3432s\n",
      "\titers: 300, epoch: 12 | loss: 0.0229403\n",
      "\tspeed: 0.0566s/iter; left time: 5279.1666s\n",
      "\titers: 400, epoch: 12 | loss: 0.0230024\n",
      "\tspeed: 0.0564s/iter; left time: 5257.1246s\n",
      "\titers: 500, epoch: 12 | loss: 0.0189091\n",
      "\tspeed: 0.0565s/iter; left time: 5260.2663s\n",
      "\titers: 600, epoch: 12 | loss: 0.0265710\n",
      "\tspeed: 0.0565s/iter; left time: 5252.5781s\n",
      "\titers: 700, epoch: 12 | loss: 0.0379141\n",
      "\tspeed: 0.0565s/iter; left time: 5251.2676s\n",
      "\titers: 800, epoch: 12 | loss: 0.0292152\n",
      "\tspeed: 0.0565s/iter; left time: 5247.3061s\n",
      "\titers: 900, epoch: 12 | loss: 0.0298963\n",
      "\tspeed: 0.0565s/iter; left time: 5238.4942s\n",
      "\titers: 1000, epoch: 12 | loss: 0.0248448\n",
      "\tspeed: 0.0566s/iter; left time: 5238.9888s\n",
      "Epoch: 12 cost time: 59.43293642997742\n",
      "Epoch: 12, Steps: 1052 | Train Loss: 0.0512082 Vali Loss: 0.0364536 Test Loss: 0.0370588\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.8828125e-08\n",
      "\titers: 100, epoch: 13 | loss: 0.0350508\n",
      "\tspeed: 0.1913s/iter; left time: 17686.3865s\n",
      "\titers: 200, epoch: 13 | loss: 0.0637045\n",
      "\tspeed: 0.0564s/iter; left time: 5213.8330s\n",
      "\titers: 300, epoch: 13 | loss: 0.0561277\n",
      "\tspeed: 0.0564s/iter; left time: 5200.4824s\n",
      "\titers: 400, epoch: 13 | loss: 0.1724705\n",
      "\tspeed: 0.0564s/iter; left time: 5200.5307s\n",
      "\titers: 500, epoch: 13 | loss: 0.0875489\n",
      "\tspeed: 0.0565s/iter; left time: 5198.0641s\n",
      "\titers: 600, epoch: 13 | loss: 0.0597992\n",
      "\tspeed: 0.0565s/iter; left time: 5192.5102s\n",
      "\titers: 700, epoch: 13 | loss: 0.0392135\n",
      "\tspeed: 0.0565s/iter; left time: 5194.0183s\n",
      "\titers: 800, epoch: 13 | loss: 0.0587506\n",
      "\tspeed: 0.0565s/iter; left time: 5189.3136s\n",
      "\titers: 900, epoch: 13 | loss: 0.0448233\n",
      "\tspeed: 0.0565s/iter; left time: 5179.3034s\n",
      "\titers: 1000, epoch: 13 | loss: 0.0877944\n",
      "\tspeed: 0.0565s/iter; left time: 5176.6010s\n",
      "Epoch: 13 cost time: 59.41203284263611\n",
      "Epoch: 13, Steps: 1052 | Train Loss: 0.0510045 Vali Loss: 0.0366955 Test Loss: 0.0370423\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.44140625e-08\n",
      "\titers: 100, epoch: 14 | loss: 0.0396849\n",
      "\tspeed: 0.1913s/iter; left time: 17488.9365s\n",
      "\titers: 200, epoch: 14 | loss: 0.0288585\n",
      "\tspeed: 0.0563s/iter; left time: 5144.7896s\n",
      "\titers: 300, epoch: 14 | loss: 0.0526916\n",
      "\tspeed: 0.0564s/iter; left time: 5149.5246s\n",
      "\titers: 400, epoch: 14 | loss: 0.0293797\n",
      "\tspeed: 0.0563s/iter; left time: 5128.9150s\n",
      "\titers: 500, epoch: 14 | loss: 0.0444979\n",
      "\tspeed: 0.0565s/iter; left time: 5143.7101s\n",
      "\titers: 600, epoch: 14 | loss: 0.0957174\n",
      "\tspeed: 0.0565s/iter; left time: 5136.3283s\n",
      "\titers: 700, epoch: 14 | loss: 0.0385092\n",
      "\tspeed: 0.0565s/iter; left time: 5130.5920s\n",
      "\titers: 800, epoch: 14 | loss: 0.0353066\n",
      "\tspeed: 0.0565s/iter; left time: 5124.6035s\n",
      "\titers: 900, epoch: 14 | loss: 0.0246506\n",
      "\tspeed: 0.0566s/iter; left time: 5129.2007s\n",
      "\titers: 1000, epoch: 14 | loss: 0.1329589\n",
      "\tspeed: 0.0565s/iter; left time: 5116.7030s\n",
      "Epoch: 14 cost time: 59.41143536567688\n",
      "Epoch: 14, Steps: 1052 | Train Loss: 0.0509646 Vali Loss: 0.0361456 Test Loss: 0.0370354\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.220703125e-08\n",
      "\titers: 100, epoch: 15 | loss: 0.0299113\n",
      "\tspeed: 0.1916s/iter; left time: 17315.9176s\n",
      "\titers: 200, epoch: 15 | loss: 0.0237076\n",
      "\tspeed: 0.0565s/iter; left time: 5101.2999s\n",
      "\titers: 300, epoch: 15 | loss: 0.0430602\n",
      "\tspeed: 0.0565s/iter; left time: 5092.5303s\n",
      "\titers: 400, epoch: 15 | loss: 0.0370036\n",
      "\tspeed: 0.0566s/iter; left time: 5097.8800s\n",
      "\titers: 500, epoch: 15 | loss: 0.0447562\n",
      "\tspeed: 0.0566s/iter; left time: 5089.6712s\n",
      "\titers: 600, epoch: 15 | loss: 0.0450323\n",
      "\tspeed: 0.0564s/iter; left time: 5071.5294s\n",
      "\titers: 700, epoch: 15 | loss: 0.0198556\n",
      "\tspeed: 0.0564s/iter; left time: 5065.9320s\n",
      "\titers: 800, epoch: 15 | loss: 0.0280243\n",
      "\tspeed: 0.0564s/iter; left time: 5055.7700s\n",
      "\titers: 900, epoch: 15 | loss: 0.0241723\n",
      "\tspeed: 0.0565s/iter; left time: 5065.0986s\n",
      "\titers: 1000, epoch: 15 | loss: 0.0461200\n",
      "\tspeed: 0.0566s/iter; left time: 5063.0524s\n",
      "Epoch: 15 cost time: 59.451738119125366\n",
      "Epoch: 15, Steps: 1052 | Train Loss: 0.0508469 Vali Loss: 0.0360107 Test Loss: 0.0371367\n",
      "Validation loss decreased (0.036144 --> 0.036011).  Saving model ...\n",
      "Updating learning rate to 6.103515625e-09\n",
      "\titers: 100, epoch: 16 | loss: 0.0631565\n",
      "\tspeed: 0.1930s/iter; left time: 17238.6885s\n",
      "\titers: 200, epoch: 16 | loss: 0.0583166\n",
      "\tspeed: 0.0567s/iter; left time: 5057.9333s\n",
      "\titers: 300, epoch: 16 | loss: 0.0487414\n",
      "\tspeed: 0.0566s/iter; left time: 5040.3741s\n",
      "\titers: 400, epoch: 16 | loss: 0.0547925\n",
      "\tspeed: 0.0565s/iter; left time: 5030.6691s\n",
      "\titers: 500, epoch: 16 | loss: 0.0263353\n",
      "\tspeed: 0.0565s/iter; left time: 5028.2890s\n",
      "\titers: 600, epoch: 16 | loss: 0.0682352\n",
      "\tspeed: 0.0565s/iter; left time: 5017.8639s\n",
      "\titers: 700, epoch: 16 | loss: 0.0352637\n",
      "\tspeed: 0.0565s/iter; left time: 5016.3909s\n",
      "\titers: 800, epoch: 16 | loss: 0.0318478\n",
      "\tspeed: 0.0564s/iter; left time: 5000.2708s\n",
      "\titers: 900, epoch: 16 | loss: 0.0422042\n",
      "\tspeed: 0.0565s/iter; left time: 5003.2246s\n",
      "\titers: 1000, epoch: 16 | loss: 0.0400876\n",
      "\tspeed: 0.0566s/iter; left time: 5008.8167s\n",
      "Epoch: 16 cost time: 59.49440312385559\n",
      "Epoch: 16, Steps: 1052 | Train Loss: 0.0508791 Vali Loss: 0.0359967 Test Loss: 0.0371602\n",
      "Validation loss decreased (0.036011 --> 0.035997).  Saving model ...\n",
      "Updating learning rate to 3.0517578125e-09\n",
      "\titers: 100, epoch: 17 | loss: 0.0232312\n",
      "\tspeed: 0.1931s/iter; left time: 17044.3720s\n",
      "\titers: 200, epoch: 17 | loss: 0.0530206\n",
      "\tspeed: 0.0566s/iter; left time: 4988.6764s\n",
      "\titers: 300, epoch: 17 | loss: 0.0355943\n",
      "\tspeed: 0.0565s/iter; left time: 4973.1269s\n",
      "\titers: 400, epoch: 17 | loss: 0.0193765\n",
      "\tspeed: 0.0566s/iter; left time: 4975.6941s\n",
      "\titers: 500, epoch: 17 | loss: 0.0920025\n",
      "\tspeed: 0.0568s/iter; left time: 4991.9931s\n",
      "\titers: 600, epoch: 17 | loss: 0.0650654\n",
      "\tspeed: 0.0567s/iter; left time: 4972.3032s\n",
      "\titers: 700, epoch: 17 | loss: 0.0478146\n",
      "\tspeed: 0.0566s/iter; left time: 4965.1220s\n",
      "\titers: 800, epoch: 17 | loss: 0.0266947\n",
      "\tspeed: 0.0577s/iter; left time: 5052.2446s\n",
      "\titers: 900, epoch: 17 | loss: 0.0504954\n",
      "\tspeed: 0.0565s/iter; left time: 4943.6984s\n",
      "\titers: 1000, epoch: 17 | loss: 0.0284158\n",
      "\tspeed: 0.0564s/iter; left time: 4926.9793s\n",
      "Epoch: 17 cost time: 59.63791251182556\n",
      "Epoch: 17, Steps: 1052 | Train Loss: 0.0508394 Vali Loss: 0.0359844 Test Loss: 0.0371194\n",
      "Validation loss decreased (0.035997 --> 0.035984).  Saving model ...\n",
      "Updating learning rate to 1.52587890625e-09\n",
      "\titers: 100, epoch: 18 | loss: 0.0392827\n",
      "\tspeed: 0.1926s/iter; left time: 16793.9002s\n",
      "\titers: 200, epoch: 18 | loss: 0.0301912\n",
      "\tspeed: 0.0565s/iter; left time: 4925.5385s\n",
      "\titers: 300, epoch: 18 | loss: 0.0373735\n",
      "\tspeed: 0.0564s/iter; left time: 4910.2632s\n",
      "\titers: 400, epoch: 18 | loss: 0.0154333\n",
      "\tspeed: 0.0565s/iter; left time: 4908.5837s\n",
      "\titers: 500, epoch: 18 | loss: 0.0448134\n",
      "\tspeed: 0.0565s/iter; left time: 4908.9131s\n",
      "\titers: 600, epoch: 18 | loss: 0.0481767\n",
      "\tspeed: 0.0564s/iter; left time: 4891.5367s\n",
      "\titers: 700, epoch: 18 | loss: 0.0648795\n",
      "\tspeed: 0.0566s/iter; left time: 4899.7350s\n",
      "\titers: 800, epoch: 18 | loss: 0.0198922\n",
      "\tspeed: 0.0564s/iter; left time: 4876.9900s\n",
      "\titers: 900, epoch: 18 | loss: 0.0240984\n",
      "\tspeed: 0.0564s/iter; left time: 4874.6625s\n",
      "\titers: 1000, epoch: 18 | loss: 0.1092847\n",
      "\tspeed: 0.0565s/iter; left time: 4873.1110s\n",
      "Epoch: 18 cost time: 59.393967151641846\n",
      "Epoch: 18, Steps: 1052 | Train Loss: 0.0511951 Vali Loss: 0.0366853 Test Loss: 0.0372201\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.62939453125e-10\n",
      "\titers: 100, epoch: 19 | loss: 0.0476908\n",
      "\tspeed: 0.1915s/iter; left time: 16497.3226s\n",
      "\titers: 200, epoch: 19 | loss: 0.0427191\n",
      "\tspeed: 0.0566s/iter; left time: 4868.9501s\n",
      "\titers: 300, epoch: 19 | loss: 0.0459446\n",
      "\tspeed: 0.0566s/iter; left time: 4864.8876s\n",
      "\titers: 400, epoch: 19 | loss: 0.0296194\n",
      "\tspeed: 0.0566s/iter; left time: 4864.0782s\n",
      "\titers: 500, epoch: 19 | loss: 0.0358005\n",
      "\tspeed: 0.0566s/iter; left time: 4850.1076s\n",
      "\titers: 600, epoch: 19 | loss: 0.0205432\n",
      "\tspeed: 0.0564s/iter; left time: 4834.7688s\n",
      "\titers: 700, epoch: 19 | loss: 0.0236354\n",
      "\tspeed: 0.0566s/iter; left time: 4839.7560s\n",
      "\titers: 800, epoch: 19 | loss: 0.0367340\n",
      "\tspeed: 0.0564s/iter; left time: 4821.7293s\n",
      "\titers: 900, epoch: 19 | loss: 0.0663547\n",
      "\tspeed: 0.0566s/iter; left time: 4833.2519s\n",
      "\titers: 1000, epoch: 19 | loss: 0.0319527\n",
      "\tspeed: 0.0567s/iter; left time: 4838.4204s\n",
      "Epoch: 19 cost time: 59.51570010185242\n",
      "Epoch: 19, Steps: 1052 | Train Loss: 0.0506936 Vali Loss: 0.0358003 Test Loss: 0.0369906\n",
      "Validation loss decreased (0.035984 --> 0.035800).  Saving model ...\n",
      "Updating learning rate to 3.814697265625e-10\n",
      "\titers: 100, epoch: 20 | loss: 0.1012968\n",
      "\tspeed: 0.1929s/iter; left time: 16419.9519s\n",
      "\titers: 200, epoch: 20 | loss: 0.0896347\n",
      "\tspeed: 0.0564s/iter; left time: 4795.6831s\n",
      "\titers: 300, epoch: 20 | loss: 0.0874099\n",
      "\tspeed: 0.0564s/iter; left time: 4791.3980s\n",
      "\titers: 400, epoch: 20 | loss: 0.0410627\n",
      "\tspeed: 0.0563s/iter; left time: 4777.2871s\n",
      "\titers: 500, epoch: 20 | loss: 0.0520221\n",
      "\tspeed: 0.0565s/iter; left time: 4788.5269s\n",
      "\titers: 600, epoch: 20 | loss: 0.0615183\n",
      "\tspeed: 0.0565s/iter; left time: 4778.1325s\n",
      "\titers: 700, epoch: 20 | loss: 0.0644828\n",
      "\tspeed: 0.0565s/iter; left time: 4774.4587s\n",
      "\titers: 800, epoch: 20 | loss: 0.0672241\n",
      "\tspeed: 0.0565s/iter; left time: 4768.0600s\n",
      "\titers: 900, epoch: 20 | loss: 0.0285436\n",
      "\tspeed: 0.0565s/iter; left time: 4762.2127s\n",
      "\titers: 1000, epoch: 20 | loss: 0.0487031\n",
      "\tspeed: 0.0565s/iter; left time: 4762.0197s\n",
      "Epoch: 20 cost time: 59.4142701625824\n",
      "Epoch: 20, Steps: 1052 | Train Loss: 0.0507850 Vali Loss: 0.0363670 Test Loss: 0.0370703\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.9073486328125e-10\n",
      "\titers: 100, epoch: 21 | loss: 0.0391862\n",
      "\tspeed: 0.1912s/iter; left time: 16070.6153s\n",
      "\titers: 200, epoch: 21 | loss: 0.0560488\n",
      "\tspeed: 0.0564s/iter; left time: 4735.7544s\n",
      "\titers: 300, epoch: 21 | loss: 0.0394673\n",
      "\tspeed: 0.0564s/iter; left time: 4730.7538s\n",
      "\titers: 400, epoch: 21 | loss: 0.3824422\n",
      "\tspeed: 0.0565s/iter; left time: 4729.5222s\n",
      "\titers: 500, epoch: 21 | loss: 0.0465542\n",
      "\tspeed: 0.0566s/iter; left time: 4735.7957s\n",
      "\titers: 600, epoch: 21 | loss: 0.0625820\n",
      "\tspeed: 0.0565s/iter; left time: 4720.8063s\n",
      "\titers: 700, epoch: 21 | loss: 0.0475348\n",
      "\tspeed: 0.0564s/iter; left time: 4711.0304s\n",
      "\titers: 800, epoch: 21 | loss: 0.0458193\n",
      "\tspeed: 0.0565s/iter; left time: 4707.8167s\n",
      "\titers: 900, epoch: 21 | loss: 0.0683779\n",
      "\tspeed: 0.0565s/iter; left time: 4706.8645s\n",
      "\titers: 1000, epoch: 21 | loss: 0.0338862\n",
      "\tspeed: 0.0565s/iter; left time: 4696.9579s\n",
      "Epoch: 21 cost time: 59.419344902038574\n",
      "Epoch: 21, Steps: 1052 | Train Loss: 0.0505346 Vali Loss: 0.0365389 Test Loss: 0.0370273\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9.5367431640625e-11\n",
      "\titers: 100, epoch: 22 | loss: 0.0312291\n",
      "\tspeed: 0.1912s/iter; left time: 15868.4027s\n",
      "\titers: 200, epoch: 22 | loss: 0.0839201\n",
      "\tspeed: 0.0563s/iter; left time: 4669.9142s\n",
      "\titers: 300, epoch: 22 | loss: 0.0368013\n",
      "\tspeed: 0.0565s/iter; left time: 4680.3510s\n",
      "\titers: 400, epoch: 22 | loss: 0.0325470\n",
      "\tspeed: 0.0565s/iter; left time: 4676.0701s\n",
      "\titers: 500, epoch: 22 | loss: 0.0360954\n",
      "\tspeed: 0.0565s/iter; left time: 4666.5304s\n",
      "\titers: 600, epoch: 22 | loss: 0.0241315\n",
      "\tspeed: 0.0563s/iter; left time: 4649.1414s\n",
      "\titers: 700, epoch: 22 | loss: 0.0608843\n",
      "\tspeed: 0.0564s/iter; left time: 4646.7102s\n",
      "\titers: 800, epoch: 22 | loss: 0.0164297\n",
      "\tspeed: 0.0564s/iter; left time: 4644.6222s\n",
      "\titers: 900, epoch: 22 | loss: 0.0373531\n",
      "\tspeed: 0.0564s/iter; left time: 4632.6904s\n",
      "\titers: 1000, epoch: 22 | loss: 0.0170440\n",
      "\tspeed: 0.0566s/iter; left time: 4644.7754s\n",
      "Epoch: 22 cost time: 59.3829607963562\n",
      "Epoch: 22, Steps: 1052 | Train Loss: 0.0509931 Vali Loss: 0.0362885 Test Loss: 0.0372022\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.76837158203125e-11\n",
      "\titers: 100, epoch: 23 | loss: 0.0995884\n",
      "\tspeed: 0.1911s/iter; left time: 15658.0580s\n",
      "\titers: 200, epoch: 23 | loss: 0.0521486\n",
      "\tspeed: 0.0565s/iter; left time: 4626.9850s\n",
      "\titers: 300, epoch: 23 | loss: 0.0357121\n",
      "\tspeed: 0.0564s/iter; left time: 4609.7515s\n",
      "\titers: 400, epoch: 23 | loss: 0.0286279\n",
      "\tspeed: 0.0564s/iter; left time: 4606.0263s\n",
      "\titers: 500, epoch: 23 | loss: 0.0561316\n",
      "\tspeed: 0.0564s/iter; left time: 4602.2350s\n",
      "\titers: 600, epoch: 23 | loss: 0.0729347\n",
      "\tspeed: 0.0565s/iter; left time: 4605.9828s\n",
      "\titers: 700, epoch: 23 | loss: 0.0306806\n",
      "\tspeed: 0.0565s/iter; left time: 4597.4849s\n",
      "\titers: 800, epoch: 23 | loss: 0.0391157\n",
      "\tspeed: 0.0565s/iter; left time: 4590.4326s\n",
      "\titers: 900, epoch: 23 | loss: 0.0504100\n",
      "\tspeed: 0.0565s/iter; left time: 4582.2753s\n",
      "\titers: 1000, epoch: 23 | loss: 0.0668829\n",
      "\tspeed: 0.0566s/iter; left time: 4584.1614s\n",
      "Epoch: 23 cost time: 59.40794038772583\n",
      "Epoch: 23, Steps: 1052 | Train Loss: 0.0509984 Vali Loss: 0.0366256 Test Loss: 0.0368291\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.384185791015625e-11\n",
      "\titers: 100, epoch: 24 | loss: 0.0211281\n",
      "\tspeed: 0.1912s/iter; left time: 15469.2222s\n",
      "\titers: 200, epoch: 24 | loss: 0.0497910\n",
      "\tspeed: 0.0566s/iter; left time: 4574.8469s\n",
      "\titers: 300, epoch: 24 | loss: 0.0387131\n",
      "\tspeed: 0.0565s/iter; left time: 4561.2603s\n",
      "\titers: 400, epoch: 24 | loss: 0.0752203\n",
      "\tspeed: 0.0564s/iter; left time: 4547.7681s\n",
      "\titers: 500, epoch: 24 | loss: 0.1312345\n",
      "\tspeed: 0.0564s/iter; left time: 4542.7414s\n",
      "\titers: 600, epoch: 24 | loss: 0.0467013\n",
      "\tspeed: 0.0565s/iter; left time: 4539.4759s\n",
      "\titers: 700, epoch: 24 | loss: 0.0457654\n",
      "\tspeed: 0.0564s/iter; left time: 4525.8829s\n",
      "\titers: 800, epoch: 24 | loss: 0.1520182\n",
      "\tspeed: 0.0565s/iter; left time: 4531.1701s\n",
      "\titers: 900, epoch: 24 | loss: 0.0284717\n",
      "\tspeed: 0.0565s/iter; left time: 4526.2296s\n",
      "\titers: 1000, epoch: 24 | loss: 0.0159808\n",
      "\tspeed: 0.0566s/iter; left time: 4528.1642s\n",
      "Epoch: 24 cost time: 59.41390419006348\n",
      "Epoch: 24, Steps: 1052 | Train Loss: 0.0507479 Vali Loss: 0.0368514 Test Loss: 0.0373996\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_custom_ftMS_sl48_ll48_pl1_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 9638\n",
      "test shape: (301, 32, 1, 1) (301, 32, 1, 1)\n",
      "test shape: (9632, 1, 1) (9632, 1, 1)\n",
      "mse:0.03717357665300369, mae:0.13028745353221893\n"
     ]
    }
   ],
   "source": [
    "for ii in range(args.itr):\n",
    "    # setting record of experiments\n",
    "    setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n",
    "                args.seq_len, args.label_len, args.pred_len,\n",
    "                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, ii)\n",
    "\n",
    "    # set experiments\n",
    "    exp = Exp(args)\n",
    "    \n",
    "    # train\n",
    "    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "    exp.train(setting)\n",
    "    \n",
    "    # test\n",
    "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "    exp.test(setting)\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Kopie von Informer.ipynb",
   "provenance": [
    {
     "file_id": "1_X7O2BkFLvqyCdZzDZvV2MB0aAvYALLC",
     "timestamp": 1650148753660
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
